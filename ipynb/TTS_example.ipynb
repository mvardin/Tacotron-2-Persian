{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTS_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvardin/Tacotron-2-Persian/blob/master/TTS_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjD0xW0cEMVT"
      },
      "source": [
        "This notebook trains Tacotron model on LJSpeech dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGiNTMShZYvj"
      },
      "source": [
        "# download LJSpeech dataset\n",
        "!wget http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "# decompress\n",
        "!tar -xjf LJSpeech-1.1.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__k0BrbfLQ-F"
      },
      "source": [
        "# create train-val splits\n",
        "!shuf LJSpeech-1.1/metadata.csv > LJSpeech-1.1/metadata_shuf.csv\n",
        "!head -n 12000 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_train.csv\n",
        "!tail -n 1100 LJSpeech-1.1/metadata_shuf.csv > LJSpeech-1.1/metadata_val.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyJwcU9pDUE-"
      },
      "source": [
        "# get TTS to your local\n",
        "!git clone https://github.com/mozilla/TTS.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV-vHTWyirQv"
      },
      "source": [
        "# install espeak backend if you like to use phonemes instead of raw characters\n",
        "!sudo apt-get install espeak-ng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwvg3-nVDL5t"
      },
      "source": [
        "%cd TTS\n",
        "# install TTS requirements\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7_Xao7uNOvX"
      },
      "source": [
        "# load the default config file and update with the local paths and settings.\n",
        "import json\n",
        "from TTS.utils.io import load_config\n",
        "CONFIG = load_config('/content/TTS/TTS/tts/configs/config.json')\n",
        "CONFIG['datasets'][0]['path'] = '../LJSpeech-1.1/'  # set the target dataset to the LJSpeech\n",
        "CONFIG['audio']['stats_path'] = None  # do not use mean and variance stats to normalizat spectrograms. Mean and variance stats need to be computed separately. \n",
        "CONFIG['output_path'] = '../'\n",
        "with open('config.json', 'w') as fp:\n",
        "    json.dump(CONFIG, fp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L3JjJOBErxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520ac0d3-6d10-4c7a-a343-3307894fbe4a"
      },
      "source": [
        "# pull the trigger\n",
        "!CUDA_VISIBLE_DEVICES=\"0\" python TTS/bin/train_tacotron.py --config_path config.json | tee training.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-05 18:44:13.674502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            " > Using CUDA:  False\n",
            " > Number of GPUs:  0\n",
            "   >  Mixed precision mode is ON\n",
            " > Git Hash: e9e0784\n",
            " > Experiment folder: ../ljspeech-ddc-August-05-2021_06+44PM-e9e0784\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:50.0\n",
            " | > mel_fmax:7600.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > stats_path:None\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " | > Found 13100 files in /content/LJSpeech-1.1\n",
            " > Using model: Tacotron2\n",
            "\n",
            " > Model has 47914548 parameters\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " > DataLoader initialization\n",
            " | > Use phonemes: True\n",
            "   | > phoneme language: en-us\n",
            " | > Number of instances : 12969\n",
            " | > Max length sequence: 187\n",
            " | > Min length sequence: 5\n",
            " | > Avg length sequence: 98.3403500655409\n",
            " | > Num. instances discarded by max-min (max=153, min=6) seq limits: 476\n",
            " | > Batch group size: 128.\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
            "\n",
            " > Number of output frames: 7\n",
            "\n",
            "\u001b[1m > TRAINING (2021-08-05 18:44:16) \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}